{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d1af59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import os\n",
    "import tarfile\n",
    "import urllib\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing, svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from sklearn.ensemble import StackingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4861971c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('CICIDS2017_18.csv')\n",
    "dataset.dropna()\n",
    "print(dataset.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f67bcb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The column to be converted to numeric data\n",
    "Column = [' Label']\n",
    "\n",
    "encoders = {}\n",
    "for col in Column:\n",
    "    encoders[col] = LabelEncoder()\n",
    "    dataset[col] = encoders[col].fit_transform(dataset[col])\n",
    "\n",
    "print(dataset.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff77112",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = dataset.corr()\n",
    "print(correlation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a70bf5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(50,30))\n",
    "heatmap = sns.heatmap(dataset.corr(), vmin=-1, vmax=1, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0340d66c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('CICIDS2017_18.csv')\n",
    "\n",
    "\n",
    "grouped_data = dataset.groupby([' Destination Port',' Total Fwd Packets',' Flow Duration',' Total Backward Packets',' Total Length of Bwd Packets',' Fwd Packet Length Mean','Init_Win_bytes_forward',' Init_Win_bytes_backward',' Bwd Packets/s',' Label'])\n",
    "aggregation_functions = {'Conc': 'count'}\n",
    "\n",
    "dataset_new = grouped_data.agg(aggregation_functions).reset_index()\n",
    "dataset_new.to_csv('updated_dataset.csv', index=False)\n",
    "\n",
    "print(dataset_new.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d2ac09",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = dataset.corr()\n",
    "print(correlation_matrix)\n",
    "plt.figure(figsize=(50,30))\n",
    "heatmap = sns.heatmap(dataset.corr(), vmin=-1, vmax=1, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd692ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = [' Label']\n",
    "\n",
    "encoders = {}\n",
    "for col in categorical_cols:\n",
    "    encoders[col] = LabelEncoder()\n",
    "    dataset[col] = encoders[col].fit_transform(dataset[col])\n",
    "\n",
    "print(dataset.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d05c370",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "labels = dataset[[\"attack\"]]\n",
    "X1 = dataset\n",
    "y1 = labels\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X1, y1, test_size=0.25)\n",
    "\n",
    "LR = LogisticRegression()\n",
    "LR.fit(X_train1, y_train1)\n",
    "y_pred = LR.predict(X_test1)\n",
    "print(y_pred)\n",
    "\n",
    "Precision = metrics.precision_score(y_test1, y_pred)\n",
    "Accuracy = metrics.accuracy_score(y_test1, y_pred)\n",
    "Sensitivity_recall = metrics.recall_score(y_test1, y_pred)\n",
    "Specificity = metrics.recall_score(y_test1,y_pred)\n",
    "F1_score = metrics.f1_score(y_test1, y_pred)\n",
    "\n",
    "\n",
    "print(f\"Precision:\",Precision)\n",
    "print(f\"Accuracy:\",Accuracy)\n",
    "print(f\"Recall:\",Sensitivity_recall)                                                                                                                                           \n",
    "print(f\"F1_score:\",F1_score)\n",
    "\n",
    "cm2 = confusion_matrix(y_test1,y_pred)\n",
    "TP2 = cm2[0][0]\n",
    "TN2 = cm2[1][1]\n",
    "FP2 = cm2[0][1]\n",
    "FN2 = cm2[1][0]\n",
    "print(\"TP :\", TP2, \" TN :\", TN2, \" FP :\", FP2, \" FN :\", FN2 )\n",
    "\n",
    "  \n",
    "\n",
    "metrics.plot_roc_curve(LR,X_test1,y_test1)\n",
    "prob1 = LR.predict_proba(X_test1)[::,1]\n",
    "auc1 = metrics.roc_auc_score(y_test1,prob1)\n",
    "print(\"area under curve :\", auc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c9ed67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "labels = dataset[[\"attack\"]]\n",
    "X2 = dataset\n",
    "y2 = labels\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, test_size=0.25)\n",
    "\n",
    "RFC = RandomForestClassifier(max_depth=2, random_state=42)\n",
    "RFC.fit(X_train2, y_train2)\n",
    "y_pred2 = RFC.predict(X_test2)\n",
    "\n",
    "print(y_pred2)\n",
    "\n",
    "#this is to get the precison, accuracy, F1_score, sensitivity and specificity\n",
    "Precision = metrics.precision_score(y_test2, y_pred2)\n",
    "Accuracy = metrics.accuracy_score(y_test2, y_pred2)\n",
    "Sensitivity_recall = metrics.recall_score(y_test2, y_pred2)\n",
    "Specificity = metrics.recall_score(y_test2, y_pred2)\n",
    "F1_score = metrics.f1_score(y_test2, y_pred2)\n",
    "\n",
    "\n",
    "print(f\"Precision:\",Precision)\n",
    "print(f\"Accuracy:\",Accuracy)\n",
    "print(f\"Recall:\",Sensitivity_recall)\n",
    "print(f\"F1_score:\",F1_score)\n",
    "\n",
    "\n",
    "color = 'white'\n",
    "matrix = plot_confusion_matrix(RFC, X_test2, y_test2, cmap=plt.cm.Reds)\n",
    "plt.show()\n",
    "\n",
    "metrics.plot_roc_curve(RFC,X_test2,y_test2)\n",
    "prob2 = RFC.predict_proba(X_test2)[::,1]\n",
    "auc2 = metrics.roc_auc_score(y_test2,prob2)\n",
    "print(\"area under curve :\", auc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e75bec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Preprocess the data\n",
    "labels = dataset[[\"attack\"]]\n",
    "X3 = dataset\n",
    "y3 = labels\n",
    "X_train3, X_test3, y_train3, y_test3 = train_test_split(X3, y3, test_size=0.25)\n",
    "\n",
    "# Build the MLP model\n",
    "NN = MLPClassifier(hidden_layer_sizes=(100,50), max_iter=1000)\n",
    "\n",
    "# Train the model\n",
    "NN.fit(X_train3, y_train3)\n",
    "y_pred = NN.predict(X_test3)\n",
    "# Evaluate the model\n",
    "\n",
    "Precision = precision_score(y_test3, y_pred)\n",
    "Accuracy = accuracy_score(y_test3, y_pred)\n",
    "Sensitivity_recall = recall_score(y_test3,y_pred)\n",
    "F1_score = f1_score(y_test3, y_pred)\n",
    "\n",
    "\n",
    "print(f\"Precision:\",Precision)\n",
    "print(f\"Accuracy:\",Accuracy)\n",
    "print(f\"Recall:\",Sensitivity_recall)\n",
    "print(f\"F1_score:\",F1_score)\n",
    "\n",
    "color = 'white'\n",
    "matrix = plot_confusion_matrix(NN, X_test3, y_test3, cmap=plt.cm.Reds)\n",
    "plt.show()\n",
    "\n",
    "metrics.plot_roc_curve(NN,X_test3,y_test3)\n",
    "prob3 = NN.predict_proba(X_test3)[::,1]\n",
    "auc3 = metrics.roc_auc_score(y_test3,prob3)\n",
    "print(\"area under curve :\", auc3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d6a552",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "X4 = dataset\n",
    "y4 = labels\n",
    "X_train4, X_test4, y_train4, y_test4 = train_test_split(X4, y4, test_size=0.25)\n",
    "\n",
    "# Define base models\n",
    "Base_models = [('RFC', RandomForestClassifier(random_state=42)),\n",
    "              ('LR', LogisticRegression(random_state=42)),\n",
    "              ('NN',MLPClassifier(random_state=42))]\n",
    "\n",
    "Meta_Model = LogisticRegression(random_state=42)\n",
    "\n",
    "\n",
    "ensemble_stacking_model = StackingClassifier(Base_models, Meta_Model)\n",
    "ensemble_stacking_model.fit(X_train4, y_train4)\n",
    "ensemble_stacking_preds = ensemble_stacking_model.predict(X_test4)\n",
    "\n",
    "# Evaluate the accuracy of the stacked model predictions\n",
    "precision = precision_score(y_test4, ensemble_stacking_preds)\n",
    "accuracy = accuracy_score(y_test4, ensemble_stacking_preds)\n",
    "recall = recall_score(y_test4, ensemble_stacking_preds)\n",
    "F1_score = f1_score(y_test4, ensemble_stacking_preds)\n",
    "\n",
    "print(\"Ensemble stacking model precision:\", precision)\n",
    "print(\"Ensemble stacking model accuracy:\", accuracy)\n",
    "print(\"Ensemble stacking model recall:\", recall)\n",
    "print(\"Ensemble stacking model F1-score:\", F1_score)\n",
    "\n",
    "\n",
    "color = 'white'\n",
    "matrix = plot_confusion_matrix(ensemble_stacking_model, X_test4, y_test4, cmap=plt.cm.Reds)\n",
    "plt.show()\n",
    "\n",
    "metrics.plot_roc_curve(ensemble_stacking_model,X_test4,y_test4)\n",
    "prob4 = ensemble_stacking_model.predict_proba(X_test4)[::,1]\n",
    "auc4 = metrics.roc_auc_score(y_test4,prob4)\n",
    "print(\"area under curve :\", auc4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f87446",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
